{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation for CLARA","text":"<p>CLARA is short for CLuster Architecture Recovery Assistent. CLARA can help by extracting component-based software architectures from applications deployed in Kubernetes clusters and exporting them into a visually appealing format. Thus, IT-architects that need insights about the components actually deployed in the Cluster can be assisted by using CLARA.</p> <p>For details on the functionality of CLARA see the concept page. For information on configuration options of CLARA see the configurations page. For information on the validation of CLARA's functionality see the validation page for the T2 Reference Architecture.</p> <p>CLARA is open-sourced under the MIT License.</p>"},{"location":"aggregation/","title":"Aggregation","text":"<p>For aggregating data from the cluster four different data sources are used in CLARA:</p> <ul> <li>Kubernetes API</li> <li>Kubernetes DNS-Server</li> <li>OpenTelemetry Traces</li> <li>anchore/syft</li> </ul> <p>Aggregations can be enabled/disabled, yet it is recommended to always use all available aggregators to get a holistic view of the examined architecture. For details see configurations.</p>"},{"location":"aggregation/platforms/kubernetes/api/","title":"API","text":"<p>CLARA utilizes the Kubernetes API to retrieve basic information about the pods, services and deployments running in the cluster.</p> <p>The fabric8 Kubernetes client is used by CLARA to communicate to the Kubernetes API.</p>"},{"location":"aggregation/platforms/kubernetes/api/#concept","title":"Concept","text":"<p>The Kubernetes API is queried for pods and services from the configured namespace (see configurations). Pods are then matched to a service and all services with their respective pods and all unmatched pods are provided into the datapipeline.</p>"},{"location":"aggregation/platforms/kubernetes/dns/","title":"DNS","text":"<p>CLARA can analyze the logs of CoreDNS (the default Kubernetes DNS server) to discover communication of components via DNS queries. For that feature to work correctly, it is crucial that the DNS server is configured to log DNS queries by enabling the <code>log</code> plugin.</p> An example ConfigMap for CoreDNS with the 'log' plugin enabled<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns\n  namespace: kube-system\ndata:\n  Corefile: |\n    .:53 {\n        log\n        errors\n        health\n        ready\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n          pods insecure\n          fallthrough in-addr.arpa ip6.arpa\n        }\n        prometheus :9153\n        forward . /etc/resolv.conf\n        cache 30\n        loop\n        reload\n        loadbalance\n    }\n</code></pre> <p>Other DNS servers</p> <p>Your cluster might come with additional DNS servers to reduce the load. A prominent example is the node-local-dns for caching DNS. There, you must also enable the <code>log</code> plugin.</p> <p>Compatible DNS servers</p> <p>Because CLARA analyzes the logged DNS queries,</p> <ol> <li>query logging must be activated</li> <li>the query logs must be compatible with the CoreDNS logs.</li> </ol> <p>Currently, CLARA analyzes all logs from the pods with the labels <code>k8s-app=kube-dns</code> or <code>k8s-app=node-local-dns</code> in the namespace <code>kube-system</code>.</p>"},{"location":"aggregation/platforms/kubernetes/dns/#managed-kubernetes-cluster","title":"Managed Kubernetes cluster","text":"<p>Using a managed Kubernetes cluster from a service provider</p> <p>When using a managed cluster from a service provider, changes to core components of Kubernetes might be not allowed directly. Please consult the documentation of your respective provider.</p>"},{"location":"aggregation/platforms/kubernetes/dns/#digitalocean","title":"DigitalOcean","text":"<p>For DigitalOcean, the correct way of enabling logging is to create a special ConfigMap:</p> ConfigMap to activate query logging for CoreDNS in a Kubernetes cluster managed by DigitalOcean<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: coredns-custom\n  namespace: kube-system\ndata:\n  log.override: |\n    log\n</code></pre>"},{"location":"aggregation/platforms/kubernetes/dns/#dns-debugging","title":"DNS debugging","text":"<p>As described in the Kubernetes Documentation, you can use dnsutils to debug DNS resolution. For CLARA, this is also a simple way of creating DNS queries explicitly and checking if CLARA detects the communication. Just create a dnsutils-pod with the following manifest:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: dnsutils\n  namespace: default\nspec:\n  containers:\n    - name: dnsutils\n      image: registry.k8s.io/e2e-test-images/jessie-dnsutils:1.7\n      command:\n        - sleep\n        - \"infinity\"\n      imagePullPolicy: IfNotPresent\n  restartPolicy: Always\n</code></pre> <p>Then you can use the following command to execute DNS queries:</p> <pre><code>kubectl exec -it dnsutils -n default -- nslookup google.com\n</code></pre> <p>Execute the following command to check the DNS server logs:</p> <pre><code>kubectl logs -l k8s-app=kube-dns -n kube-system\n</code></pre>"},{"location":"aggregation/platforms/kubernetes/dns/#concept","title":"Concept","text":"<p>The log DNS analysis uses the obtained information from the Kubernetes API to match the hostnames and ip-addresses in a DNS log to components of the cluster. An example log can look like this and provides disclosure about the source and target of a communication. <pre><code>[INFO] 10.244.0.19:35065 - 3179 \"A IN kubernetes.default.svc.cluster.local.svc.cluster.local. udp 72 false 512\" NXDOMAIN qr,aa,rd 165 0.0000838s\n</code></pre></p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/","title":"OpenTelemetry","text":"<p>CLARA can utilize OpenTelemetry traces as data source for finding components and to some extent component types, as well as communications between components. For that feature to work correctly, it is crucial to have instrumented applications and an OpenTelemetry Collector running in the cluster as described below.</p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#concept","title":"Concept","text":"<p>\"OpenTelemetry is an Observability framework and toolkit designed to create and manage telemetry data such as traces, metrics, and logs.\"  Traces and metrics are generated by each component individually and are forwarded to an OpenTelemetry collector, which processes the telemetry data and distributes it to a backend which utilizes it. CLARA can be seen as such a backend, which offers a gRPC endpoint for the oTel-collector to forward the traces to. CLARA then iterates over the traces and extracts information about components and their communications from that.</p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#setup","title":"Setup","text":"<p>When using OpenTelemetry for CLARA you first need to ensure your software components are instrumented with OpenTelemetry traces. If not consider using OpenTelemetry auto-instrumentation.</p> <p>OpenTelemetry Semantic Conventions</p> <p>Because OpenTelemetry traces' attributes are not standardized, it is recommended to use tracing with the OpenTelemetry semantic conventions for CLARA. If your services do not provide them, you can try to set up the OpenTelemetry auto-instrumentation on top of your system.</p> <p>Second, ensure that there is an OpenTelemetry collector with the matching configuration is running in your cluster. Third, when you use CLARA on a local machine and do not deploy in the cluster, you need to forward the traces from the OpenTelemetry collector to your local machine. The open-source tool ktunnel can be used to achieve this.</p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#opentelemetry-collector","title":"OpenTelemetry Collector","text":"<p>The OpenTelemetry collector is a default component provided by OpenTelemetry itself. For CLARA only traces are used, thus the minimal configuration  The image can be used to deploy a container with a suitable configuration as shown below. Examples for service and deployment configurations can be found in clara/deployment/open-telemetry-collector/deployment.yml</p> An example ConfigMap for the oTel-collector deployment<pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otel-collector-conf\n  labels:\n    app: otel-collector-conf\n    component: otel-collector-conf\ndata:\n  otel-collector-conf: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n\n    processors:\n\n    exporters:\n      otlp:\n        endpoint: \"localhost:7878\"\n        tls:\n          insecure: true\n\n    service:\n      pipelines:\n        traces:\n          receivers: [otlp]\n          processors: []\n          exporters: [otlp]\n</code></pre>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#ktunnel","title":"ktunnel","text":"<p>ktunnel is an open-source tool that enables reverse port-forwarding to extract data out of kubernetes clusters. In order to use CLARA on a local machine, a ktunnel sidecar can be attached towards the OpenTelemetry collector deployment using  <code>ktunnel inject deployment otel-collector-deployment 7878 -n &lt;namespace&gt;</code> For further information see the ktunnel docs. </p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#opentelemetry-auto-instrumentation","title":"OpenTelemetry Auto-instrumentation","text":"<p>OpenTelemetry Auto-instrumentation can be used to generate OpenTelemetry traces on software components that are not instrumented themselves in Kubernetes clusters. This works by applying sidecar containers to each yet to be instrumented service that capture the network traffic and generate traces from that. For documentation on installation please see the official docs from OpenTelemetry.</p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#aggregation-algorithms","title":"Aggregation Algorithms","text":"<p>After the OpenTelemetry-aggregator finished collecting the traces, the algorithm will iterate over all traces and extract architectural information from it. An OpenTelemetry spans can be of one of five kinds, Producer, Consumer, Client, Server and Internal. Internal spans are ignored, Client- and Server-spans as well as Producer- and Consumer- spans are analyzed seperated from each other, as described below.</p>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#client-server","title":"Client-Server","text":"<p>Spans of Client and Server kind are analyzed the following way:</p> <p>A client as well as a server span can disclose information about the sending component as well as the respective other component in the communication. Therefore, from each span two possible components are obtained, that receive all the information available.</p> <p>As there is no definitive standard for the naming and the values of span-attributes, the following logic is applied to extract information from span attributes:</p> <ul> <li>For each seeked information (hostname, port, ip-address, and path) of the server and the client a list of often used key names is provided (e.g. server.address, url.path, etc.). </li> <li>The spans attributes are then filtered for those key-names and if they match, regexes are applied in order to find the specific attribute.</li> <li>Two component-objects are created and with all available information and simply added to a list of found components.</li> <li>A relation (communication) object with the client-name and if available the server-name, otherwise the server hostname or ip-address is added.</li> </ul>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#producer-consumer","title":"Producer-Consumer","text":"<p>Producers and Consumers of message-oriented communications are specifically tagged, because there is no directly observable communication between the source and the target component. Based on the semantic conventions, however, a producer-span contains the messaging-destination which can be used to obtain the communication. Therefore, the recovery looks as follows:</p> <ul> <li>Three components are created, the source, the target and the message-broker </li> <li>A Messaging relation (communications) containing the source, the target and the messaging system. </li> </ul>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#merging","title":"Merging","text":"<p>As each analyzed span creates at least two component objects, those need to be merged into a consistent pattern. The merging is done the following way:</p> <ul> <li>All component objects without a service name are tried to be matched to component having a service name via the hostname, the ip-address or the endpoint-list.</li> <li>Components that can't be matched will be dealt with afterward.</li> </ul>"},{"location":"aggregation/platforms/kubernetes/opentelemetry/#mapping","title":"Mapping","text":"<p>The component objects finally need to be mapped to the CLARA-wide internal component and communication representation.  Component objects containing a service-name are mapped to an \"internal\" component object, components without a service-name are mapped to an \"external\" one. Communications are mapped if a matching component via service-name or hostname for source and target can be found.</p>"},{"location":"aggregation/platforms/kubernetes/syft/","title":"SBOM","text":"<p>CLARA can utilize anchore/syft to create SBOM files in SPDX format from the recovered components. This is done to extract the dependencies and external libraries of the recovered architecture.</p>"},{"location":"aggregation/platforms/kubernetes/syft/#concept","title":"Concept","text":"<p>In order to get the library information of each component, CLARA passes the recovered image and version tag to syft. The syft binary then fetches the image from docker-hub and analyzes its contents and creates the SPDX files. Lastly, the SPDX files for the components are read by CLARA and each library and version from is added to the respective component.</p>"},{"location":"aggregation/platforms/kubernetes/syft/#setup","title":"Setup","text":"<p>Install the binary from anchore/syft for your respective OS: macOS: <pre><code>brew install syft\n</code></pre> All OS: <pre><code>curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin \n</code></pre> For configuration options please see the configurations page.</p>"},{"location":"concept/","title":"Concept","text":"<p>CLARA itself is a data pipeline that collects information about an application deployed in a Kubernetes cluster from different data sources (i.e. the Kubernetes API, the Kubernetes internal DNS server and OpenTelemetry traces), merges them, filters them and exports them to visually display the architecture of the examined application.</p>"},{"location":"concept/#datapipeline","title":"Datapipeline","text":"<p>The datapipeline of CLARA consists of the four main steps:</p> <ul> <li>Aggregation </li> <li>Merging </li> <li>Filtering </li> <li>Export </li> </ul> <p></p>"},{"location":"configuration/","title":"Configuration","text":"<p>The typical configuration for CLARA is in the YAML format. Below, each available option is explained. All options with a default value are optional.</p> <p>Sensitive Information &amp; Environment Variables</p> <p>Sensitive information, like usernames and passwords, don't belong into configuration files! For that reason, each configuration option can be specified by an environment variable. Instead of the actual value, the BASH-like syntax <code>${NAME_OF_THE_ENV_VARIABLE}</code> can be used to specify the environment variable.</p> <p>Interpolation and specifying default values is possible as well, just have a look here! There you can also find other ways to set up the configuration to be effective, like referencing and substituting other parts of the configuration to make it more DRY.</p>"},{"location":"configuration/#general-configuration-options","title":"General configuration options","text":"app.log-config <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: Whether the whole configuration that CLARA will use should be logged at startup (at the info-level).</li> </ul> app.block-after-finish <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: Whether the CLARA process should keep running after all exports are finished.   This is useful when CLARA itself is running e.g. in Kubernetes and the Pod should not terminate because of the automatic restarts.</li> </ul>"},{"location":"configuration/#configuring-the-aggregation","title":"Configuring the aggregation","text":""},{"location":"configuration/#platform-kubernetes","title":"Platform: Kubernetes","text":"aggregation.platforms.kubernetes.include-kube-namespaces <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: Whether the namespaces with the <code>kube</code>-prefix should also get scanned by CLARA.   Must be set to true when every namespace should be scanned, even when namespaces has the <code>*</code>-wildcard.</li> </ul> aggregation.platforms.kubernetes.namespaces <ul> <li>Type: List of Strings</li> <li>Default: empty List</li> <li>Description: List all namespaces which CLARA should scan.   To just scan all namespaces (except the <code>kube</code>-namespaces) set just the <code>*</code>-wildcard as the only element.   The <code>*</code> needs to be in quotes.</li> </ul>"},{"location":"configuration/#aggregator-kubernetes-api-optional","title":"Aggregator: Kubernetes API (optional)","text":"aggregation.platforms.kubernetes.aggregators.kube-api.enable <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable this aggregator without removing all of its associated configuration.</li> </ul>"},{"location":"configuration/#aggregator-dns-optional","title":"Aggregator: DNS (optional)","text":"aggregation.platforms.kubernetes.aggregators.dns.enable <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable this aggregator without removing all of its associated configuration.</li> </ul> aggregation.platforms.kubernetes.aggregators.dns.logs-since-time <ul> <li>Type: String (formatted as RFC3339, like <code>2024-01-01T00:00:00Z</code>)</li> <li>Default: empty String</li> <li>Description: The DNS aggregator works by analyzing the logs of the Kubernetes DNS server which must be configured to log the queries.   This option defines how recent the logs must be to be considered by CLARA.   If this option is just an empty String (the default), all available logs will be used, which can lead to unwanted side effects, like old logs from a previous version of the deployment polluting the recovered architecture.</li> </ul> aggregation.platforms.kubernetes.aggregators.dns.use-logs-from-file <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: Simple way to switch if the DNS logs should be read from a file instead the Kubernetes API directly.</li> </ul> aggregation.platforms.kubernetes.aggregators.dns.path-to-dns-logs <ul> <li>Type: String</li> <li>Default: empty String</li> <li>Description: The DNS aggregator when used with files instead of the API must obtain an absolute path to the file.</li> </ul>"},{"location":"configuration/#aggregator-opentelemetry-optional","title":"Aggregator: OpenTelemetry (optional)","text":"aggregation.platforms.kubernetes.aggregators.open-telemetry.enable <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable this aggregator without removing all of its associated configuration.</li> </ul> aggregation.platforms.kubernetes.aggregators.open-telemetry.listen-port <ul> <li>Type: Integer (must be a valid port number)</li> <li>Description: The port CLARA will listen to incoming spans sent by an OpenTelemetry collector.</li> </ul> aggregation.platforms.kubernetes.aggregators.open-telemetry.listen-duration <ul> <li>Type: String (format here)</li> <li>Description: Amount of time CLARA should listen to incoming spans sent by an OpenTelemetry collector.</li> </ul>"},{"location":"configuration/#aggregator-syft-sbom-optional","title":"Aggregator: syft-sbom (optional)","text":"aggregation.platforms.kubernetes.aggregators.syft-sbom.enable <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable this aggregator without removing all of its associated configuration.</li> </ul> aggregation.platforms.kubernetes.aggregators.syft-sbom.sbom-file-path <ul> <li>Type: String (a valid relative or absolute path e.g. \"sbom/\")</li> <li>Description: The path where CLARA stores the generated SPDX-JSON files.</li> </ul> aggregation.platforms.kubernetes.aggregators.syft-sbom.use-stored-sbom-files <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: States if the SPDX-JSON files for aggregating the libraries should be newly generated or not.</li> </ul>"},{"location":"configuration/#configuring-the-merge","title":"Configuring the merge","text":"merge.comparison-strategy <ul> <li>Type: String (one of <code>Equals</code>, <code>Prefix</code>, <code>Suffix</code>, <code>Contains</code>)</li> <li>Description: Strategy for matching names of components aggregated by different aggregators.   <code>Equals</code> needs the same names, <code>Prefix</code> and <code>Suffix</code> need to have matching strings on the start or the end respectively, <code>Contains</code> needs that one string is part of the other.</li> </ul> merge.show-messaging-communications-directly <ul> <li>Type: Boolean</li> <li>Description: If <code>true</code>, CLARA will define communications that go via a message broker directly between the components and removes the communications to the message broker. If <code>false</code> it show the communications via the message broker. </li> </ul>"},{"location":"configuration/#configuring-the-filter","title":"Configuring the filter","text":"filter.remove-component-endpoints <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: If <code>true</code>, the endpoints of the components are filtered out before the export, to improve visibility in complex architectures.</li> </ul> filter.remove-component-versions <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: If <code>true</code>, the versions of the components are filtered out before the export, to reduce updates when components are often released.</li> </ul> filter.remove-components-by-names <ul> <li>Type: List of Strings</li> <li>Default: empty List</li> <li>Description: list of components that should be filtered out before the export (e.g. otel-collector-service).</li> </ul>"},{"location":"configuration/#configuring-the-export","title":"Configuring the export","text":"export.on-empty <ul> <li>Type: Boolean</li> <li>Default: false</li> <li>Description: If <code>true</code>, CLARA will export the recovered architecture using the enabled exporters, even if the architecture is completely empty.   This could be useful for debugging purposes.</li> </ul>"},{"location":"configuration/#exporter-graphviz-optional","title":"Exporter: GraphViz (optional)","text":"export.exporters.graphviz.enable <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable this exporter without removing all of its associated configuration.</li> </ul> export.exporters.graphviz.output-type <ul> <li>Type: String (one of <code>BMP</code>, <code>DOT</code>, <code>GIF</code>, <code>JPG</code>, <code>JPEG</code>, <code>JSON</code>, <code>PDF</code>, <code>PNG</code>, <code>SVG</code>, <code>TIFF</code>)</li> <li>Description: Output format of the export. <code>SVG</code> is known to work well and in most situations the best choice.</li> </ul> export.exporters.graphviz.output-file <ul> <li>Type: String</li> <li>Description: The file location (absolute or relative path) of the GraphViz output.</li> <li>Example: <code>generated/architecture.svg</code></li> </ul>"},{"location":"configuration/#exporter-gropius-optional","title":"Exporter: Gropius (optional)","text":"export.exporters.gropius.enable <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable this exporter without removing all of its associated configuration.</li> </ul> export.exporters.gropius.project-id <ul> <li>Type: String</li> <li>Description: The ID of the Gropius-project to export the recovered architecture to.</li> </ul> export.exporters.gropius.graphql-backend-url <ul> <li>Type: String (a valid URL)</li> <li>Description: The URL where CLARA can interact with the GraphQL-API of Gropius.</li> </ul> export.exporters.gropius.graphql-backend-authentication export.exporters.gropius.graphql-backend-authentication.authentication-url <ul> <li>Type: String (a valid URL)</li> <li>Description: The URL where CLARA can obtain an authentication token from the Gropius-backend via client credentials.</li> </ul> export.exporters.gropius.graphql-backend-authentication.client-id <ul> <li>Type: String</li> <li>Description: The OAuth client ID for obtaining an authentication token.</li> </ul> export.exporters.gropius.graphql-backend-authentication.client-secret <ul> <li>Type: String</li> <li>Description: The OAuth client ID's secret for obtaining an authentication token.</li> </ul> export.exporters.gropius.component-handling <ul> <li>Type: String (one of <code>Delete</code> or <code>Modify</code>)</li> <li>Description: The mode how should be dealt with already existing components. Delete deletes and re-creates the old one, modify changes attributes.</li> </ul> export.exporters.gropius.export-libraries <ul> <li>Type: Boolean</li> <li>Default: true</li> <li>Description: Simple way to disable exporting libraries, as this is a data-intensive process and not always wanted.</li> </ul>"},{"location":"configuration/#a-full-example-config","title":"A full example config","text":"<pre><code>app:\n  log-config: true\n  block-after-finish: false\n\naggregation:\n  platforms:\n    kubernetes:\n      include-kube-namespaces: false\n      namespaces:\n        - abc\n        - xyz\n      aggregators:\n        kube-api:\n          enable: true\n        dns:\n          enable: true\n          logs-since-time: 2024-02-01T00:00:00Z\n        open-telemetry:\n          enable: true\n          listen-port: 7878\n          listen-duration: 45 minutes\n        syft-sbom:\n          enable: true\n          sbom-file-path: sbom/\n          use-stored-sbom-files: false\n\nmerge:\n  comparison-strategy: Equals\n  show-messaging-communications-directly: true\n\nfilter:\n  remove-component-endpoints: false\n  remove-components-by-names:\n    - otel-collector-service\n\nexport:\n  on-empty: false\n  exporters:\n    graphviz:\n      enable: true\n      output-type: SVG\n      output-file: generated/architecture.svg\n    gropius:\n      enable: true\n      project-id: aaaaaaaa-1111-bbbb-2222-cccccccccccc\n      graphql-backend-url: http://my.backend.com:8080/graphql\n      graphql-backend-authentication:\n        authentication-url: http://my.backend.com:3000/authenticate/oauth/xxxxxxxx-1111-yyyy-2222-zzzzzzzzzzzz/token\n        client-id: ${CLARA_GROPIUS_GRAPHQL_CLIENT_ID}\n        client-secret: ${CLARA_GROPIUS_GRAPHQL_CLIENT_SECRET}\n</code></pre>"},{"location":"export/","title":"Export","text":"<p>CLARA offers two different ways for exporting the aggregated Architecture:</p> <ul> <li>GraphViz to create a quick SVG export of the architecture.</li> <li>Gropius to create a dynamic Gropius representation of the architecture, exported and added to the configured Gropius project. For more details on Gropius visit the GitHub Page.</li> </ul>"},{"location":"export/gropius/","title":"Gropius Export","text":"<p>Gropius is an open-source cross-component issue management system for component-based architectures. In order to enable managing cross-component dependencies, users can model component-based software architectures in a Gropius project, e.g. via the API. For more details on Gropius visit the GitHub Page.</p> <p>For configuration options of the export please check out the configurations page.</p>"},{"location":"export/gropius/#data-model","title":"Data Model","text":"<p>The data model of Gropius consists of components which can be specified with templates as well as relations between those components, also configurable via templates. A component must have a component and a repository-URL in order to be added to a project, which resembles an architecture.</p> <p>CLARA components are mapped to Gropius-components like this:</p> CLARA Metamodel Gropius Metamodel InternalComponent Component \u00a0\u00a0\u00a0\u00a0InternalComponent.Name \u00a0\u00a0\u00a0\u00a0Component.Name \u00a0\u00a0\u00a0\u00a0InternalComponent.IpAddress \u00a0\u00a0\u00a0\u00a0Component.Description \u00a0\u00a0\u00a0\u00a0InternalComponent.Version \u00a0\u00a0\u00a0\u00a0Component.ComponentVersion \u00a0\u00a0\u00a0\u00a0InternalComponent.Namespace MISSING \u00a0\u00a0\u00a0\u00a0InternalComponent.Endpoints MISSING (Note, that Gropius is capable of modeling interfaces, yet due to a lack of time this is not performed in the current work.) MISSING \u00a0\u00a0\u00a0\u00a0Component.RepositoryURL (Example URL) \u00a0\u00a0\u00a0\u00a0InternalComponent.Type \u00a0\u00a0\u00a0\u00a0Component.ComponentTemplate \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Type.Database \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Database Temp. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Type.Microservice \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Microservice Temp. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Type.Messaging \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Messaging Temp. \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0null \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Base Component Temp. \u00a0\u00a0\u00a0\u00a0InternalComponent.Libraries \u00a0\u00a0\u00a0\u00a0Components \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Library.Version \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Component.ComponentVersion \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Library.Name \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Component.Name \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Library.Name \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Component.Description MISSING \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Component.ComponentTemplate (Library Temp.) \u00a0\u00a0\u00a0\u00a0InternalComponent.Library \u00a0\u00a0\u00a0\u00a0Relation \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0InternalComponent.Version \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Relation.Start \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Library.Version \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Relation.End MISSING \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Relation.RelationTemplate (Includes Temp.) ExternalComponent Component \u00a0\u00a0\u00a0\u00a0ExternalComponent.Name \u00a0\u00a0\u00a0\u00a0Component.Name \u00a0\u00a0\u00a0\u00a0ExternalComponent.Domain \u00a0\u00a0\u00a0\u00a0Component.Description \u00a0\u00a0\u00a0\u00a0ExternalComponent.Type \u00a0\u00a0\u00a0\u00a0Component.ComponentTemplate (Misc Temp.) \u00a0\u00a0\u00a0\u00a0ExternalComponent.Version \u00a0\u00a0\u00a0\u00a0Component.ComponentVersion Communication Relation \u00a0\u00a0\u00a0\u00a0Communication.Source.Version \u00a0\u00a0\u00a0\u00a0Relation.Start \u00a0\u00a0\u00a0\u00a0Communication.Target.Version \u00a0\u00a0\u00a0\u00a0Relation.End MISSING \u00a0\u00a0\u00a0\u00a0Relation.RelationTemplate (Calls Temp.) <p>The Gropius GraphQL API is utilized by CLARA in order to export the recovered architectures into a Gropius project.</p>"},{"location":"export/gropius/#export-flow","title":"Export Flow","text":"<p>The export works sketched like this based on the respective configuration:</p> <ul> <li>for all components recovered by CLARA:</li> <li>delete or update component</li> <li>create or update component version</li> <li>add component version to project</li> <li>add relations for all components </li> </ul> <p>For all CRUD operations there are predefined GraphQL queries which are transformed into Kotlin Models using this GraphQl gradle plugin  and executed using this GraphQL Kotlin Spring client. The GraphQL queries are located in the clara-graphql directory.</p>"},{"location":"export/svg/","title":"SVG Export","text":"<p>The GraphViz SVG exporter exports a superficial representation of the architecture as displayed in the example image below.</p> <p>Legend:</p> <ul> <li>Arrow: Communication from source component to destination component</li> <li>Octagon: Component</li> <li>component-name</li> <li>component-ip-address</li> <li>component-endpoints</li> <li>Rectangle: External Component not in the namespace</li> <li>Outer Square: Kubernetes Namespace of the collected data</li> </ul> <p>For configuration options please check out the configurations page.</p>"},{"location":"filtering/","title":"Filtering","text":"<p>Filtering is applied as third step in the data pipeline, see concept. Filters can be added/removed by plug-and-play. For details see the configurations page.</p>"},{"location":"filtering/#filtering-options","title":"Filtering options","text":"<ul> <li>Remove Component Endpoints: The attribute \"Endpoints\" is filtered out (in order to make the SVG export more visually appealing). </li> <li>Remove Components by Name: Components can be filtered out if they are not directly part of the application (e.g. the OpenTelemetry Collector).</li> </ul>"},{"location":"merging/","title":"Merging","text":"<p>Merging is applied as third step in the data pipeline, as shown in concept. Merging is mandatory, as the results of the different aggregations need to be merged into a homogenous data format to retrieve a holistic picture.  Further, duplications are removed. For details on configuration possibilities see the configurations page.</p>"},{"location":"merging/#concept","title":"Concept","text":"<p>The following concepts and data operations are applied in the merging step of CLARA:  </p> <ul> <li>Base and Comparison Components </li> <li>Comparing </li> <li>Merging</li> <li>Dealing with Renamed Components </li> <li>Leftover Components </li> <li>Communications </li> <li>Adjusting Messaging Communications</li> </ul>"},{"location":"merging/#base-and-comparison-components","title":"Base and Comparison Components","text":"<p>In CLARA the merging of two detected components by different aggregators is defined as merging a comparison object on top of the base object.  In general, the components aggregated from the Kubernetes API are considered as the base component and OpenTelemetry components are considered as compare components. This is the case, because the Kubernetes API can be perceived as the ground truth about what is deployed in the cluster.</p>"},{"location":"merging/#comparing","title":"Comparing","text":"<p>In the comparison step for every Kubernetes component a matching OpenTelemetry component is searched. The matching is currently only be done by the name. Thereby CLARA can be configured to match only equal names or also match if one name contains the other (e.g. cart-pod-12345 and cart).</p>"},{"location":"merging/#merging_1","title":"Merging","text":"<p>In the merging step both component objects from Kubernetes and from OpenTelemetry are merged into a new final component object. Thereby, the Kubernetes component is providing the service-name, Kubernetes namespace, IP-address, and if applicable the version. The OpenTelemetry Component provides the endpoints and most likely the service type (e.g. database).</p>"},{"location":"merging/#dealing-with-renamed-components","title":"Dealing with Renamed Components","text":"<p>If a merged component was matched via a \"contains\"-pattern matching it is likely, that the final component has a different name then the OpenTelemetry component. Thus, the relations discovered between OpenTelemetry components need to be adjusted to match the new naming.</p>"},{"location":"merging/#leftover-components","title":"Leftover Components","text":"<p>All components that could not be matched are simply mapped to a final component, with whatever attributes are available, to not lose any information.</p>"},{"location":"merging/#communications","title":"Communications","text":"<p>Communications do not really have to be merged, as they are simply stacked upon each other in the exporter and do not contain any meta-information except source and target.</p>"},{"location":"merging/#adjusting-messaging-communications","title":"Adjusting Messaging Communications","text":"<p>Communications that are tagged as messaging communication, are also adjusted in the merger. CLARA can be configured to either show communications via a message broker or filter out the message broker and show the communications between the communications directly. The latter can make it easier to understand the real communication flows of an application, especially if everything runs via a message broker.</p>"},{"location":"setup/","title":"Setup instructions for CLARA step-by-step","text":"<p>These instructions will walk you through the initial installation and setup of the CLARA project. A deployed instance of the Gropius project as well as access to a kubernetes cluster are required.</p>"},{"location":"setup/#1-prerequisites","title":"1. Prerequisites","text":""},{"location":"setup/#11-getting-clara","title":"1.1. Getting CLARA","text":"<ul> <li> <p>Clone the CLARA repository.</p> <p><pre><code>git clone https://github.com/ccims/clara.git\n</code></pre> or <pre><code>git clone git@github.com:ccims/clara.git\n</code></pre></p> </li> </ul> <p>Java Installation</p> <p>Make sure you have at least a Java 21 JVM installed and configured on your machine.</p>"},{"location":"setup/#12-kube-api","title":"1.2. kube-api","text":"<ul> <li>Ensure you have administrative rights for your Kubernetes cluster.</li> <li>Ensure you have configured the target namespace you want to analyze, in the context of your local kube-config.</li> </ul>"},{"location":"setup/#13-install-ktunnel","title":"1.3. Install ktunnel:","text":"<p>ktunnel allows CLARA to stream data from inside the cluster to the outside, thus not needing to be deployed inside the cluster.</p> <p>Either use homebrew: <pre><code>brew tap omrikiei/ktunnel &amp;&amp; brew install omrikiei/ktunnel/ktunnel\n</code></pre> or fetch the binaries from the release page.</p>"},{"location":"setup/#2-aggregator-setup-and-configuration","title":"2. Aggregator Setup and Configuration","text":"<p>CLARA relies on different aggregation components, that each need individual preparation. Although each aggregator is not mandatory, it is recommended to go through the setup of all following aggregators.</p>"},{"location":"setup/#21-opentelemetry-auto-instrumentation","title":"2.1 OpenTelemetry auto-instrumentation","text":"<p>CLARA utilizes the opentelemetry auto-instrumentation to add spans to the cluster's communication.</p> <ul> <li>Check if cert manager is installed in the cluster. If not run:     <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.14.4/cert-manager.yaml\n</code></pre></li> <li>Install the OpenTelemetry operator into the cluster:     <pre><code>kubectl apply -f https://github.com/open-telemetry/opentelemetry-operator/releases/latest/download/opentelemetry-operator.yaml\n</code></pre></li> <li>Install the OpenTelemetry collector into the target namespace:     <pre><code>kubectl -n &lt;target-namespace&gt; apply -f &lt;path-to-clara&gt;/deployment/open-telemetry-collector/configmap.yml\nkubectl -n &lt;target-namespace&gt; apply -f &lt;path-to-clara&gt;/deployment/open-telemetry-collector/deployment.yml   \n</code></pre></li> <li>Add the instrumentation object into the target namespace:     <pre><code>kubectl -n &lt;target-namespace&gt; apply -f &lt;path-to-clara&gt;/deployment/open-telemetry-collector/autoinstrumentation.yml\n</code></pre></li> <li>In the target namespace, instrument all existing deployments with the respective technology/framework of the application by configuring each <code>deployment.yaml</code> individually:     <pre><code>spec:\n  template:\n    metadata:\n      annotations: \n        # choose one or more of the following for each deployment\n        instrumentation.opentelemetry.io/inject-java: \"true\"\n        instrumentation.opentelemetry.io/inject-dotnet: \"true\" \n        instrumentation.opentelemetry.io/inject-go: \"true\" \n        instrumentation.opentelemetry.io/inject-nodejs: \"true\" \n        instrumentation.opentelemetry.io/inject-python: \"true\" \n</code></pre></li> </ul>"},{"location":"setup/#22-coredns","title":"2.2. CoreDNS","text":"<p>Ensure you can access and if necessary configure the kube-dns in the kube-system namespace. When using a managed cluster from a service provider, changes to core components of Kubernetes might not be allowed directly. Please consult the documentation of your respective provider.</p> <ul> <li>Ensure you can see the logs of your kube-dns component and it logs DNS requests by running:     <pre><code>kubectl logs -l k8s-app=kube-dns -n kube-system\n</code></pre></li> <li>Ensure you see logs of this format:     <pre><code>[INFO] 10.244.0.19:35065 - 3179 \"A IN kubernetes.default.svc.cluster.local.svc.cluster.local. udp 72 false 512\" NXDOMAIN qr,aa,rd 165 0.0000838s\n</code></pre></li> <li>If you don't see such logs, configure your kube-dns accordingly, based on your service-provider (you can check this docs page, too).</li> <li>Note, that if there is zero traffic in the cluster probably no DNS resolution logs will be there.</li> </ul>"},{"location":"setup/#23-install-anchoresyft","title":"2.3. Install anchore/syft","text":"<p>CLARA uses syft to generate SBOMs from container images.</p> <ul> <li>Install the binary from anchore/syft for your respective OS: macOS:     <pre><code>brew install syft\n</code></pre>     All OS:     <pre><code>curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin \n</code></pre></li> </ul>"},{"location":"setup/#3-run-clara","title":"3. Run CLARA","text":"<ul> <li>CLARA comes with a default config, yet it is recommended to check the configuration options and adjust them to your needs.    It is also recommended to make some dry runs with stripped down, minimal config to see if the configuration works properly.    For configuration options see: configurations page.    The config file of CLARA can be found at <code>&lt;path-to-clara&gt;/clara-app/src/main/resources/config.yml</code></li> <li>In this <code>config.yml</code> please insert your specific URLs and authorization information for accessing your deployed Gropius instance.    Sensitive credentials are prepared to be set as environment variables.</li> <li>To build CLARA run in the clara dictionary:     <pre><code>./gradlew clean build standaloneJar\n</code></pre></li> <li>If you want to use the Gropius exporter, set the Gropius environment variables:     <pre><code>export CLARA_GROPIUS_GRAPHQL_CLIENT_ID=&lt;your-client-id&gt;\nexport CLARA_GROPIUS_GRAPHQL_CLIENT_SECRET=&lt;your-client-secret&gt;\nexport CLARA_GROPIUS_PROJECT_ID=&lt;your-project-id&gt;\n</code></pre></li> <li>Start CLARA by executing the application:     <pre><code>java -jar clara-app/build/libs/clara-app-*.jar\n</code></pre></li> <li>Run ktunnel in parallel to ensure spans are forwarded to CLARA:      <pre><code>ktunnel inject deployment otel-collector-deployment 7878 -n &lt;your-namespace&gt;\n</code></pre></li> </ul>"},{"location":"validation/t2-reference-architecture/","title":"Evaluation against T2-Reference-Architecture","text":"<p>CLARA has been evaluated against the T2-Project Reference-Architecture (Microservices).</p> <p>Follow this guideline step-by-step to recreate the evaluation of CLARA using the T2-Project, locally on a minikube cluster.</p>"},{"location":"validation/t2-reference-architecture/#step-by-step-setup-and-execution-instructions","title":"Step-By-Step Setup and Execution Instructions","text":"<p>The setup consists of the Gropius setup, the minikube setup, the T2-Project setup, and the CLARA setup.</p>"},{"location":"validation/t2-reference-architecture/#1-gropius-setup","title":"1. Gropius Setup:","text":""},{"location":"validation/t2-reference-architecture/#11-getting-gropius","title":"1.1 Getting Gropius","text":"<ul> <li> <p>Clone the Gropius repository recursive with all submodules.</p> <p><pre><code>git clone --recurse-submodules https://github.com/ccims/gropius.git\n</code></pre>   or <pre><code>git clone --recurse-submodules git@github.com:ccims/gropius.git\n</code></pre></p> </li> </ul> <p>Docker Installation</p> <p>Make sure you have a local container environment (e.g. Docker) installed and configured on your machine.</p> <ul> <li>Locally deploy the Gropius testing environment using docker-compose:     <pre><code>docker-compose -f docker-compose-testing.yaml up -d\n</code></pre></li> <li>Check availability by visiting http://localhost:4200.</li> </ul>"},{"location":"validation/t2-reference-architecture/#12-creating-gropius-oauth-client","title":"1.2 Creating Gropius OAuth Client","text":"<ul> <li>To authenticate against Gropius you need an OAuth2 client. You can create one in the Gropius UI.</li> <li>Open Gropius in your browser under http://localhost:4200 and log in as the default admin (admin/admin).</li> <li>Click on the tab <code>Admin</code> in the top menu, then select <code>OAuth2</code> on the left menu.</li> <li>On the right menu hit the <code>+</code> to create a new OAuth2 client.</li> <li>In the opening dialog enter the following:</li> <li>Name: <code>CLARA</code></li> <li>Redirect URLs: <code>http://localhost:7878</code></li> <li>Client credential flow user: type 'admin' and select the <code>Admin</code> account.</li> <li>Check <code>requires secret</code>.</li> <li>Check <code>is valid</code>.</li> <li>Hit <code>Create auth client</code>.</li> <li>Now, you should see an entry named <code>CLARA</code> in the list.</li> <li>On the right, click the <code>ID</code>-icon and copy the client-id and store it where you find it again.</li> <li>On the right, click the key-symbol and create a new secret access key. Copy it immediately as you won't see it again and store it next to the client-id. </li> </ul>"},{"location":"validation/t2-reference-architecture/#13-create-gropius-project","title":"1.3 Create Gropius Project","text":"<ul> <li>Create a new Project in Gropius by again opening the Gropius UI under http://localhost:4200 and logging in as the default admin (admin/admin). </li> <li>Click on the tab <code>Projects</code> in the top menu.</li> <li>On the right menu hit the <code>+</code> to create a Project:</li> <li>Enter any name that suites you.</li> <li>Enter any description that suites you. </li> <li>For repository URL simply enter: <code>https://example.org</code></li> <li>Hit <code>create project</code>.</li> <li>Click on the newly created project in the list and copy the project's UUID from the URL and store it where you find it again.</li> </ul>"},{"location":"validation/t2-reference-architecture/#14-import-gropius-default-templates","title":"1.4 Import Gropius Default Templates","text":"<ul> <li>The Gropius metamodel is ontological and works with templates.</li> <li>To install the templates necessary for CLARA, you need to import them into Gropius.</li> <li>Clone the template-importer.     <pre><code>git clone https://github.com/ccims/template-importer.git\n</code></pre>   or     <pre><code>git clone git@github.com:ccims/template-importer.git\n</code></pre></li> <li>Make sure you have npm installed.</li> <li>In the base directory of the template-importer run:     <pre><code>npm i\nnpm run build\n</code></pre></li> <li>Next, run the import script. Make sure you use your configured OAuth2 client-id and -secret:     <pre><code>npm start &lt;path-to-clara&gt;/gropius_templates.json &lt;your-client-id&gt; &lt;your-client-secret&gt; http://localhost:4200\n</code></pre></li> </ul>"},{"location":"validation/t2-reference-architecture/#2-setup-minikube-and-kubectl","title":"2. Setup minikube and kubectl","text":"<ul> <li>Install minikube for your local environment as described in their official docs.</li> <li>Ensure that kubectl is installed on your machine.</li> <li>Start minikube with your preferred configuration. The default is:     <pre><code>minikube start\n</code></pre></li> <li>Verify minikube is the configured context:     <pre><code>kubectl ctx\n</code></pre></li> <li>Create a new namespace called <code>clara</code> in the minikube cluster:     <pre><code>kubectl create ns clara\n</code></pre></li> </ul>"},{"location":"validation/t2-reference-architecture/#3-t2-project-configuration","title":"3. T2-Project Configuration","text":"<ul> <li>Clone the T2-Project's devops subproject.     <code>sh   git clone https://github.com/t2-project/devops.git</code>   or     <pre><code>git clone git@github.com:t2-project/devops.git\n</code></pre></li> <li>Navigate to the directory <code>devops/k8s/t2-microservices/base</code>, where you find the deployment manifests for the T2-Project microservices.</li> <li>Insert the following into each of the <code>Deployment</code> part of the respective yaml file (except for the postgres services):     <pre><code>spec:\n  template:\n    metadata:\n      annotations: \n        instrumentation.opentelemetry.io/inject-java: \"true\"\n</code></pre></li> <li>You will deploy the microservices below in 5. Deploy T2-Project after the CLARA setup.</li> </ul>"},{"location":"validation/t2-reference-architecture/#4-clara-setup","title":"4. CLARA Setup","text":"<ul> <li>Setup CLARA on your local machine as described in steps 1 and 2 on the setup page.</li> <li>Use <code>clara</code> as the target namespace.</li> <li>In step 2.1 you can skip the injection of the annotations into the deployments, as you have already done this.</li> <li>DO NOT RUN CLARA YET, as the T2-Project is not yet deployed.</li> </ul>"},{"location":"validation/t2-reference-architecture/#5-deploy-t2-project","title":"5. Deploy T2-Project","text":"<ul> <li>In the T2-Project's <code>devops</code>-repository navigate back to <code>devops/k8s</code> and execute the following to install the T2-Project into the cluster:     <pre><code>chmod +x ./start-microservices.sh\n./start-microservices.sh clara\n</code></pre></li> <li>Describe the pods with <code>kubectl -n clara describe pod &lt;any-pod&gt;</code> and ensure they have <code>OTLP</code> attributes inside the description-yaml.</li> <li>If not, check the OpenTelemetry auto-instrumentation troubleshooting page.</li> <li>For further questions regarding the T2-Project, check the official deployment instructions.</li> </ul>"},{"location":"validation/t2-reference-architecture/#6-execution","title":"6. Execution","text":""},{"location":"validation/t2-reference-architecture/#61-create-traffic","title":"6.1 Create Traffic","text":"<ul> <li>Create traffic during the execution by manually clicking around the web shop.</li> <li>To do that, create a port forward to the T2-Project UI from your shell:     <pre><code>kubectl -n clara port-forward svc/ui 7000:80\n</code></pre></li> <li>Open the shop under http://localhost:7000/ui/products and click around the shop and order some tea to create traffic.</li> </ul>"},{"location":"validation/t2-reference-architecture/#62-execute-clara","title":"6.2 Execute CLARA","text":"<ul> <li>Execute CLARA as described in step 3 on the setup page. </li> <li>You can use the default config as provided. No need to change anything.</li> <li>Check the CLARA logs during execution and ensure spans are coming in, when clicking around the web shop. </li> </ul>"},{"location":"validation/t2-reference-architecture/#63-visit-the-results","title":"6.3 Visit the results","text":"<ul> <li>CLARA should now execute without any issues.</li> <li>If so, in the end open the Gropius UI under http://localhost:4200 and open your project.</li> <li>You should see the recovered architecture of the T2-Project in the UI now.</li> </ul>"}]}